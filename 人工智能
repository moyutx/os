# 将模型转换为 ONNX 格式并保存
def with_cache_convert(model: AttentionWithCache, save_path='model.onnx') -> None:
    model.eval()  # 设置模型为评估模式
    
    # 创建虚拟输入数据
    dummy_input = torch.randn(1, 10, model.hidden_size, device=device)  # 假设输入的 batch_size=1, sequence_length=10
    dummy_key_cache = torch.randn(1, model.num_heads, 0, model.head_dim, device=device)  # 初始 key 缓存为空
    dummy_value_cache = torch.randn(1, model.num_heads, 0, model.head_dim, device=device)  # 初始 value 缓存为空
    
    # 导出 ONNX 模型
    torch.onnx.export(
        model,  
        (dummy_input, dummy_key_cache, dummy_value_cache),  # 传入输入参数
        save_path,  
        export_params=True,  # 导出权重参数
        opset_version=12,  # 使用 ONNX opset 版本 12
        do_constant_folding=True,  # 进行常量折叠优化
        input_names=["hidden_states", "key_cache", "value_cache"],  # 定义输入名称
        output_names=["output", "new_key_cache", "new_value_cache"],  # 定义输出名称
        dynamic_axes={  # 设置动态轴，以支持不同批次大小和序列长度
            "hidden_states": {0: "batch_size", 1: "sequence_length"},  # hidden_states 的 batch 维度和序列长度维度是动态的
            "key_cache": {0: "batch_size", 2: "past_sequence_length"},  # key_cache 的 batch 维度和 past 序列长度维度是动态的
            "value_cache": {0: "batch_size", 2: "past_sequence_length"},  # value_cache 的 batch 维度和 past 序列长度维度是动态的
            "output": {0: "batch_size", 1: "sequence_length"},  # 输出的 batch 维度和序列长度维度是动态的
            "new_key_cache": {0: "batch_size", 2: "total_sequence_length"},  # new_key_cache 的 batch 维度和完整序列长度是动态的
            "new_value_cache": {0: "batch_size", 2: "total_sequence_length"},  # new_value_cache 的 batch 维度和完整序列长度是动态的
        }
    )

# 使用 ONNX 运行模型，并返回输出及更新的缓存
def onnx_test_with_cache(hidden_states: np.ndarray, key_cache: Optional[np.ndarray] = None, value_cache: Optional[np.ndarray] = None, model_path: str='model.onnx') -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    sess = ort.InferenceSession(model_path)  # 加载 ONNX 模型
    
    # 初始化 key_cache 和 value_cache，如果未提供，则创建空缓存
    if key_cache is None:
        key_cache = np.zeros((hidden_states.shape[0], 8, 0, hidden_states.shape[2] // 8), dtype=np.float32)
    if value_cache is None:
        value_cache = np.zeros((hidden_states.shape[0], 8, 0, hidden_states.shape[2] // 8), dtype=np.float32)
    
    # 构造 ONNX 模型的输入
    inputs = {
        "hidden_states": hidden_states,
        "key_cache": key_cache,
        "value_cache": value_cache
    }
    
    # 运行 ONNX 推理
    outputs = sess.run(None, inputs)
    
    # 返回模型输出以及更新后的缓存
    return outputs[0], outputs[1], outputs[2]
